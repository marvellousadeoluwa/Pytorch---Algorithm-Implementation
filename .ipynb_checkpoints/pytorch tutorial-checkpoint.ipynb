{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cc6a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'__version__' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144ce75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ba71d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f263fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba493e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,3)\n",
    "y = torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c054b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3573, 0.8858, 1.4305],\n",
      "        [0.6426, 1.1111, 1.0093],\n",
      "        [1.2704, 0.9013, 1.2325]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62239a7",
   "metadata": {},
   "source": [
    "2. Numpy - tensor conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850cda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) <class 'torch.Tensor'>\n",
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a, type(a))\n",
    "b = a.numpy()\n",
    "print(b, type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc448e",
   "metadata": {},
   "source": [
    " 3. Autograd - calculate gradient (requires_grad = True param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8dcd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3859, -0.9858, -1.3800], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "c = torch.randn(3, requires_grad = True)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e008198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3859, 1.0142, 0.6200], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cf = c + 2\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7af942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.5813,  1.0432,  0.2383], grad_fn=<MulBackward0>)\n",
      "tensor(4.9543, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "grd = cf *cf ** 2\n",
    "print(grd)\n",
    "grd = grd.mean()\n",
    "print(grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfaf07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9543, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "grd.backward()\n",
    "print(grd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67bac83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every computation we do , pytorch creates a computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f571726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "492fffc7",
   "metadata": {},
   "source": [
    "# Using Numpy alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "676f81e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch 1, weight = 1.200, loss = 30.00000000\n",
      "epoch 3, weight = 1.872, loss = 0.76800019\n",
      "epoch 5, weight = 1.980, loss = 0.01966083\n",
      "epoch 7, weight = 1.997, loss = 0.00050332\n",
      "epoch 9, weight = 1.999, loss = 0.00001288\n",
      "Prediction after training: f(5) = 9.999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w*X\n",
    "# f = 2 * X\n",
    "\n",
    "X = np.array([1,2,3,4], dtype = np.float32)\n",
    "Y = np.array([2,4,6,8], dtype = np.float32)\n",
    "\n",
    "w = 0.0 # init weight\n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss\n",
    "def loss(y, y_pred):\n",
    "    # mean squared error\n",
    "    return ((y_pred - y) ** 2).mean()\n",
    "\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2)\n",
    "# dJ/dw = 1/N 2x (w*x - y) \n",
    "\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "print(f\"prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "\n",
    "# Training \n",
    "lr = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradient\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights\n",
    "    w -= lr * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch+1}, weight = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "\n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba4c6af",
   "metadata": {},
   "source": [
    "# Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af20bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch 1, weight = 0.300, loss = 30.00000000\n",
      "epoch 11, weight = 1.665, loss = 1.16278565\n",
      "epoch 21, weight = 1.934, loss = 0.04506890\n",
      "epoch 31, weight = 1.987, loss = 0.00174685\n",
      "epoch 41, weight = 1.997, loss = 0.00006770\n",
      "epoch 51, weight = 1.999, loss = 0.00000262\n",
      "epoch 61, weight = 2.000, loss = 0.00000010\n",
      "epoch 71, weight = 2.000, loss = 0.00000000\n",
      "epoch 81, weight = 2.000, loss = 0.00000000\n",
      "epoch 91, weight = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# pytorch allows us not to manually calculate gradient\n",
    "\n",
    "import torch\n",
    "\n",
    "# f = w*X\n",
    "# f = 2 * X\n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # init weight\n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss\n",
    "def loss(y, y_pred):\n",
    "    # mean squared error\n",
    "    return ((y_pred - y) ** 2).mean()\n",
    "\n",
    "\n",
    "# gradient, no need to manually calcultae\n",
    "\n",
    "print(f\"prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "\n",
    "# Training \n",
    "lr = 0.01\n",
    "n_iters = 100 # backprog is not as exact as the numerical, so do more iterations\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()# calculate loss wrt w dl/dw\n",
    "    \n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "    # zero gradient, so gradient is 0 over all iterations\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, weight = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "\n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df07f0",
   "metadata": {},
   "source": [
    "# Pytorch Can do the entire pipeline for us\n",
    "- TRAINING pipeline:\n",
    "- ==> Design model training data (input, output size, forward pass)\n",
    "- ==> Construct Loss and Optimizer\n",
    "- ==> Training Loop\n",
    "    - forward pass: compute prediction\n",
    "    - backward pass: gradient\n",
    "    - update weights\n",
    "- Replace manual loss and optimizer computation with pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a04ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5) = 0.000\n",
      "epoch 1, weight = 0.300, loss = 30.00000000\n",
      "epoch 11, weight = 1.665, loss = 1.16278565\n",
      "epoch 21, weight = 1.934, loss = 0.04506890\n",
      "epoch 31, weight = 1.987, loss = 0.00174685\n",
      "epoch 41, weight = 1.997, loss = 0.00006770\n",
      "epoch 51, weight = 1.999, loss = 0.00000262\n",
      "epoch 61, weight = 2.000, loss = 0.00000010\n",
      "epoch 71, weight = 2.000, loss = 0.00000000\n",
      "epoch 81, weight = 2.000, loss = 0.00000000\n",
      "epoch 91, weight = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# f = w*X\n",
    "# f = 2 * X\n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True) # init weight\n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "print(f\"prediction before training: f(5) = {forward(5):.3f}\")\n",
    "\n",
    "# Training \n",
    "lr = 0.01\n",
    "n_iters = 100 # backprog is not as exact as the numerical, so do more iterations\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr= lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()# calculate loss wrt w dl/dw\n",
    "    \n",
    "    # no need to manually update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradient, so gradient is 0 over all iterations\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}, weight = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "\n",
    "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04049f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: n_samples: 4 n_samples: 1\n",
      "prediction before training: f(5) = 0.039\n",
      "epoch 1, weight = 0.348, loss = 30.52545357\n",
      "epoch 11, weight = 1.617, loss = 0.81771147\n",
      "epoch 21, weight = 1.825, loss = 0.04747442\n",
      "epoch 31, weight = 1.861, loss = 0.02601473\n",
      "epoch 41, weight = 1.870, loss = 0.02401680\n",
      "epoch 51, weight = 1.875, loss = 0.02260640\n",
      "epoch 61, weight = 1.879, loss = 0.02129025\n",
      "epoch 71, weight = 1.882, loss = 0.02005107\n",
      "epoch 81, weight = 1.886, loss = 0.01888399\n",
      "epoch 91, weight = 1.889, loss = 0.01778483\n",
      "Prediction after training: f(5) = 9.778\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# f = w*X\n",
    "# f = 2 * X\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32) # reshape as no of features\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype= torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print('Input size:', 'n_samples:', n_samples, \"n_samples:\",n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# remove manual forward pass and w\n",
    "model = nn.Linear(input_size, output_size) # one layer\n",
    "\n",
    "print(f\"prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training \n",
    "lr = 0.01\n",
    "n_iters = 100 # backprog is not as exact as the numerical, so do more iterations\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()# calculate loss wrt w dl/dw\n",
    "    \n",
    "    # no need to manually update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradient, so gradient is 0 over all iterations\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}, weight = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "\n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25833983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: n_samples: 4 n_samples: 1\n",
      "prediction before training: f(5) = 0.048\n",
      "epoch 1, weight = 0.160, loss = 27.16475677\n",
      "epoch 11, weight = 1.360, loss = 0.94269013\n",
      "epoch 21, weight = 1.563, loss = 0.25030079\n",
      "epoch 31, weight = 1.606, loss = 0.21923785\n",
      "epoch 41, weight = 1.622, loss = 0.20605038\n",
      "epoch 51, weight = 1.634, loss = 0.19404608\n",
      "epoch 61, weight = 1.645, loss = 0.18275142\n",
      "epoch 71, weight = 1.656, loss = 0.17211434\n",
      "epoch 81, weight = 1.666, loss = 0.16209643\n",
      "epoch 91, weight = 1.676, loss = 0.15266159\n",
      "Prediction after training: f(5) = 9.350\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# f = w*X\n",
    "# f = 2 * X\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32) # reshape as no of features\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype= torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print('Input size:', 'n_samples:', n_samples, \"n_samples:\",n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# custom model - to design pytorch model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        # defien layer\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.lin(X)\n",
    "    \n",
    "model = LinearRegressionModel(input_size, output_size)\n",
    "    \n",
    "    \n",
    "print(f\"prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
    "\n",
    "# Training \n",
    "lr = 0.01\n",
    "n_iters = 100 # backprog is not as exact as the numerical, so do more iterations\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= lr)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradient = backward pass\n",
    "    l.backward()# calculate loss wrt w dl/dw\n",
    "    \n",
    "    # no need to manually update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradient, so gradient is 0 over all iterations\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f\"epoch {epoch+1}, weight = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "\n",
    "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b113c20",
   "metadata": {},
   "source": [
    "# Linear Regression - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a70c5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "937f901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100,\n",
    "                                            n_features=1,\n",
    "                                            noise=20,\n",
    "                                           random_state=42)\n",
    "# convert numpy to tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "# reshape\n",
    "y = y.view(y.shape[0], 1) # 1 column\n",
    "\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d372b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sTEP 1 - Model\n",
    "\n",
    "model = nn.Linear(in_features= n_features, out_features= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41322b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2. Loss and Optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e6c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3. Training loop\n",
    "# forward pass\n",
    "# backward pass\n",
    "# weight update\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y, y_pred)\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # weight update\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad() # never forget\n",
    "    \n",
    "    if (epoch + 1 % 10) == 0: # every 10 steps\n",
    "        print(f\"epoch: {epoch + 1}, loss= {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9507976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "predicted = model(X).detach() # make requires_grad = False\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fa432",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ab2a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# forward pass\n",
    "# backward pass\n",
    "# weight update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "962091e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b98811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "bc = datasets.load_breast_cancer()\n",
    "\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "825e3b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "n_samples, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd663dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27c6dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66e9a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84996dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one col\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1187bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - linear combo of weight and bias\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1) # one class label at the end\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        \n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f175d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# loss and optimizer\n",
    "lr = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54dce825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss = 0.4770\n",
      "epoch 20, loss = 0.4294\n",
      "epoch 30, loss = 0.3935\n",
      "epoch 40, loss = 0.3653\n",
      "epoch 50, loss = 0.3424\n",
      "epoch 60, loss = 0.3232\n",
      "epoch 70, loss = 0.3070\n",
      "epoch 80, loss = 0.2930\n",
      "epoch 90, loss = 0.2808\n",
      "epoch 100, loss = 0.2699\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # backward passsss\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch {epoch +1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bb45dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9649\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    \n",
    "    # accuracy\n",
    "    acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ad555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4a6e86",
   "metadata": {},
   "source": [
    "# Batch Training - Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83117081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bca746dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('Wine_data.csv', delimiter=\",\",\n",
    "                        dtype= np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:,1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # dataset[] call with index\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6799fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-fd1eefd78997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "# a look\n",
    "\n",
    "#dataset = WineDataset()\n",
    "\n",
    "#first_data = dataset[0]\n",
    "#features, labels = first_data\n",
    "\n",
    "#features, labels\n",
    "\n",
    "# dataloader\n",
    "\n",
    "dataset = WineDataset()\n",
    "\n",
    "dataloader = DataLoader(dataset= dataset,\n",
    "                       batch_size=4,\n",
    "                       shuffle=True,\n",
    "                       num_workers = 2)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "data = dataiter.next()\n",
    "\n",
    "features, labels = data\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd698437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb4197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7823ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9a114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0fc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214d7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
